{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7323ef54",
   "metadata": {},
   "source": [
    "# Handwritten number classification : Fully connected Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43094f1d",
   "metadata": {},
   "source": [
    "Classification of digits written by hand is one of the most popular beginnerÂ´s approch to learn machine learning. In this tutorial we will use fully connected **Neural Network** in order to classify the image of handwritten numbers. \n",
    "\n",
    "Methodology:\n",
    "- Data Processing\n",
    "- Model Architecture: network design\n",
    "- Training : network\n",
    "- Evaluating the result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3fdb17",
   "metadata": {},
   "source": [
    " For science behinid the convolution neural network, please check this videos:\n",
    "        https://www.youtube.com/watch?v=2-mzxsSWVCU&list=PL2zRqk16wsdo3VJmrusPU6xXHk37RuKzi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d2c868",
   "metadata": {},
   "source": [
    "###  1) Importing the necessary library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3b45b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the necessary library\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "#note you might need to install tenserflow in your anaconda environment, if so type following in the anaconda prompt\n",
    "# pip install tensorflow==2.7 (CPU version)\n",
    "# pip install tensorflow-gpu==2.7 (GPU version)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a506008e",
   "metadata": {},
   "source": [
    " ### 2) load the MINST dataset\n",
    " \n",
    "Lets load the MINST dataset which contain 60,000 training images and 10,000 test images of handwritten digits. The image are greyscale of 28*28 pixels and labelled with the corresponding digit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff565080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 1s 0us/step\n",
      "11501568/11490434 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Load MNIST handwritten digit data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c30f2f",
   "metadata": {},
   "source": [
    "Before processing the data, lets have a look at the dataset itself. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45c7099f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n"
     ]
    }
   ],
   "source": [
    "# to see the shape of image \n",
    "for i in range(5):\n",
    "  print(X_train[i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e3a5ad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   3  18  18  18 126 136\n",
      "  175  26 166 255 247 127   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  30  36  94 154 170 253 253 253 253 253\n",
      "  225 172 253 242 195  64   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253 251\n",
      "   93  82  82  56  39   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  18 219 253 253 253 253 253 198 182 247 241\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43 154\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  14   1 154 253  90   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0  11 190 253  70   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  35 241 225 160 108   1\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0  81 240 253 253 119\n",
      "   25   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  45 186 253 253\n",
      "  150  27   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93 252\n",
      "  253 187   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 249\n",
      "  253 249  64   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183 253\n",
      "  253 207   2   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  39 148 229 253 253 253\n",
      "  250 182   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253 253 201\n",
      "   78   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  23  66 213 253 253 253 253 198  81   2\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  18 171 219 253 253 253 253 195  80   9   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0  55 172 226 253 253 253 253 244 133  11   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0 136 253 253 253 212 135 132  16   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "# see how the picture matrix looks like\n",
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294732db",
   "metadata": {},
   "source": [
    "### 3) Processing the Data\n",
    "\n",
    "Changing the labels data (y_train & y_test) into one-hot format by using the ***to_categorical*** function.\n",
    "The labels which are represented by integers from 0 to 9 will be converted into a vector of 10 values, where the value at the index corresponding to the label is 1, and all other values are 0.\n",
    "\n",
    "Eg: the label 2 would be represented as $[0, 0, 1, 0, 0, 0, 0, 0, 0, 0]$ in one-hot encoded form.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "168f8b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot format\n",
    "y_train=to_categorical(y_train,num_classes=10)\n",
    "y_test=to_categorical(y_test,num_classes=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32d95088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# checking how the one-hot format looks like\n",
    "for i in range(5):\n",
    "  print(y_test[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4968c9b7",
   "metadata": {},
   "source": [
    "### 4) Neural Network Architecture\n",
    "\n",
    "A fully connected neural network consists of one or more hidden layers, where each neuron in a layer is connected to every other neurons from the previous layer.\n",
    "\n",
    "- Initially start by creating a simple Neural Network model by using the ***sequential*** class. It will create a neural network model where the layers can be added in sequence. This class allows us to create a neural network by stacking layers on top of each other.\n",
    "\n",
    "\n",
    "- To add  layers to the model, we should use ***model.add()*** \n",
    "\n",
    "\n",
    "- Since first layer is the input layer, we have use out dataset as input, hence we have input it in away that network can comprehend. Use ***flatten*** for the first layer. The Flatten layer in Keras is used to convert a multidimensional input tensor into a single-dimensional output tensor. The Flatten layer takes an input tensor of shape (batch_size, height, width, channels) and flattens it into a single-dimensional tensor of shape (batch_size, height * width * channels). Eg: For an input tensor of shape (32, 28, 28, 3), where 32 is the batch size, 28 is the height and width of each image, and 3 is the number of color channels. The Flatten layer will convert this tensor into a single-dimensional tensor of shape (32, 2352), where 2352 is the product of the height, width, and channels.\n",
    "\n",
    "\n",
    "- Instead of using ***flatten*** as first layer, once can individually process the input data and provide the relevent shape. Eg: (batch_size, height * width * channels) by using **X_train = X_train.reshape((60000, 784))**. In that case you just add the layer and provide the shape. But in this tutorial we prefer to use ***flatten*** instead.\n",
    "\n",
    "\n",
    "-  Besdie first layer, the number of units (neurons) to be added is assigned after ***Dense*** in each layer. Rember the number of neurons in the last layer should be same as the desired output classification.\n",
    "\n",
    "\n",
    "- As activation function has to be assigned for each layers, eg: relu, softmax, etc. Choose which activation function is the best option in each of the layers.\n",
    "\n",
    "\n",
    "- Finally, it is always nice to print the summery, whihc provides details about the number of parameters being solved.\n",
    "\n",
    "\n",
    "- For more detials on ***Keras*** model building, please check: https://keras.io/guides/sequential_model/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60c6160f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 784)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 5)                 3925      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                60        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,985\n",
      "Trainable params: 3,985\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=(28,28)))\n",
    "model.add(Dense(5, activation='sigmoid'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9febe3ad",
   "metadata": {},
   "source": [
    "Adding **Batch Normalization** layer to the neural network model.\n",
    "\n",
    "Batch Normalization operates on mini-batches of data during training, and normalizes the input to each layer by subtracting the mean and dividing by the standard deviation. This can help prevent the values of the input from becoming too large or too small, which can lead to issues such as vanishing gradients or exploding gradients. The normalized output is then rescaled and shifted using learnable parameters, which allow the network to adapt the normalization to the specific task at hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c657f3ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_1 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 784)              3136      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 5)                 3925      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                60        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,121\n",
      "Trainable params: 5,553\n",
      "Non-trainable params: 1,568\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model with batch normalization layer\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=(28,28)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(5, activation='sigmoid'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d556ad",
   "metadata": {},
   "source": [
    "**Compile the model**\n",
    "\n",
    "- ***optimizer***: This is the optimization algorithm used to update the weights in the neural network during training. In this case, we are using Stochastic Gradient Descent (SGD).\n",
    "\n",
    "\n",
    "- In the example implementation you provided, the ***categorical_crossentropy*** loss function is used. This is a commonly used loss function for multi-class classification problems, where the goal is to predict the class label of an input example from a set of possible classes. The ***categorical_crossentropy*** loss function measures the difference between the true class distribution and the predicted class distribution. The predicted class distribution is obtained by applying the softmax function to the output of the model's final layer, which produces a probability distribution over the possible classes.\n",
    "\n",
    "\n",
    "- The ***accuracy*** metric will be used to monitor the model's performance during training and validation. This iswhich is the proportion of correct predictions among the total number of predictions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b9dfd79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compilation of model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b664d1f8",
   "metadata": {},
   "source": [
    "### 5) Training\n",
    "\n",
    "-  Lets train our neural network using the fit function for the provided dataset. \n",
    "\n",
    "\n",
    "- The ***epochs*** refers to number of iteration desired.\n",
    "\n",
    "\n",
    "- ***validation_data***: This is a tuple of input and target data for the validation set. The validation set is used to evaluate the performance of the model during training and to prevent overfitting. If specified, the validation loss and metrics will be computed and displayed during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "54313350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 1.3354 - acc: 0.7003 - val_loss: 0.9140 - val_acc: 0.8237\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.8298 - acc: 0.8096 - val_loss: 0.6795 - val_acc: 0.8426\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.6796 - acc: 0.8235 - val_loss: 0.5939 - val_acc: 0.8465\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.6122 - acc: 0.8318 - val_loss: 0.5519 - val_acc: 0.8502\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.5702 - acc: 0.8403 - val_loss: 0.5195 - val_acc: 0.8603\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.5469 - acc: 0.8437 - val_loss: 0.5102 - val_acc: 0.8583\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.5280 - acc: 0.8496 - val_loss: 0.4921 - val_acc: 0.8663\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.5124 - acc: 0.8528 - val_loss: 0.4823 - val_acc: 0.8670\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.5001 - acc: 0.8555 - val_loss: 0.4772 - val_acc: 0.8714\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4917 - acc: 0.8575 - val_loss: 0.4684 - val_acc: 0.8704\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1faad76ff70>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the Neural Network model\n",
    "model.fit(X_train, y_train, epochs=10, validation_data=(X_test,y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcef70c4",
   "metadata": {},
   "source": [
    "### 6) Prediction\n",
    "\n",
    "\n",
    "Prediction over the test dataset using the trained model. Ways to evaluate the prediction are as follows:\n",
    "\n",
    "- Evaluating the performance on the test dataset by using ***model.evaluate()*** function.\n",
    "\n",
    "The verbosity is set to 0 to suppress output, and store the results in the score variable. The test loss is a scalar value representing the error of the model on the test set, and the test accuracy is the proportion of correctly classified examples in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dbb535f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.46844083070755005\n",
      "Test accuracy: 0.8704000115394592\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302cb5fc",
   "metadata": {},
   "source": [
    "\n",
    "- ***model.predict*** checks the output of the predict function.\n",
    "\n",
    "It applies the trained model to the test set inputs and produces corresponding predicted outputs, which are then stored in the predictions variable. Each element in the predictions array represents the model's predicted probability for a particular class for a given input sample.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a298e36d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.88269978e-03 7.57552742e-04 7.16626644e-04 ... 9.46979403e-01\n",
      "  4.81791655e-03 2.80204751e-02]\n",
      " [7.74373114e-02 2.12473140e-04 8.47456872e-01 ... 2.06604658e-04\n",
      "  7.24069588e-03 2.51075071e-05]\n",
      " [3.52038041e-05 9.51123118e-01 1.14705078e-02 ... 1.27982786e-02\n",
      "  5.94684109e-03 1.04665253e-02]\n",
      " ...\n",
      " [2.18381523e-04 1.84690894e-03 5.61186171e-05 ... 7.46268127e-03\n",
      "  1.23017691e-02 4.83039737e-01]\n",
      " [7.37977971e-04 1.13111571e-04 7.85704528e-04 ... 1.20604076e-04\n",
      "  1.71003222e-01 4.17893054e-04]\n",
      " [4.39281110e-04 7.02878533e-05 4.89577977e-03 ... 4.92144409e-07\n",
      "  2.24580220e-03 1.38388437e-04]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluation \n",
    "predictions = model.predict(X_test)\n",
    "print(predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8903fc1",
   "metadata": {},
   "source": [
    "Once you have these predicted probabilities, you can use them to make predictions on new, unseen data by selecting the class with the highest probability. For example, you might use the ***argmax()*** function to find the index of the highest predicted probability for each input sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "478a2357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7 2 1 ... 9 5 6]\n"
     ]
    }
   ],
   "source": [
    "predictions = np.argmax(predictions, axis=1)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216da5e7",
   "metadata": {},
   "source": [
    "**Plotting**: \n",
    "display the first 10 images from the test dataset showing the prediction on top of each image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fd89f192",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x288 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display some predictions on test data\n",
    "fig, axes = plt.subplots(ncols=10, sharex=False, sharey=True, figsize=(20, 4))\n",
    "for i in range(10):\n",
    "    axes[i].set_title(predictions[i])\n",
    "    axes[i].imshow(X_test[i], cmap='gray')\n",
    "    axes[i].get_xaxis().set_visible(False)\n",
    "    axes[i].get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1bb137",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
